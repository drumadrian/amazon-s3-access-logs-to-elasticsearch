AWSTemplateFormatVersion: "2010-09-09"

Description: >
  This template builds an AWS CodePipeline pipeline that implements a continuous 
  delivery release process. This is the build pipeline for the development 
  of the system. 
  
  This pipeline is also used to install this system for end users. 
  References:
    https://www.mikeapted.com/aws/2017/02/05/codecommit-codebuild-s3/



Parameters: 

  AppStackName:
    Description: A name for the AWS SAM stack
    Type: String
    Default: "logmydata-app"

  BranchName:
    Description: A name for the codecommit repo Branch
    Type: String
    Default: "master"

  GitHubRepositoryHTTPSurl:
    Description: A https URL to clone the GitHub repo with code to deploy
    Type: String
    Default: "https://github.com/drumadrian/amazon-s3-access-logs-to-elasticsearch.git"


Resources:

  ArtifactStoreBucket:
    Type: AWS::S3::Bucket
    Properties:
      VersioningConfiguration:
        Status: Enabled


  cleanupBucketOnDelete:
    DependsOn: cleanupBucketOnDeleteLambda
    Type: Custom::cleanupbucket
    Properties:
      ServiceToken: 
       Fn::GetAtt: 
          - "cleanupBucketOnDeleteLambda"
          - "Arn"
      BucketName: !Sub '${ArtifactStoreBucket.Arn}'


  cleanupBucketOnDeleteLambda:
    DependsOn: ArtifactStoreBucket
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile: !Sub |
          #!/usr/bin/env python
          # -*- coding: utf-8 -*-

          import json
          import boto3
          from botocore.vendored import requests

          def empty_delete_buckets(bucket_name):
              """
              Empties and deletes the bucket
              :param bucket_name:
              :param region:
              :return:
              """
              print "trying to delete the bucket {0}".format(bucket_name)
              # s3_client = SESSION.client('s3', region_name=region)
              s3_client = boto3.client('s3')
              # s3 = SESSION.resource('s3', region_name=region)
              s3 = boto3.resource('s3')

              try:
                  bucket = s3.Bucket(bucket_name).load()
              except ClientError:
                  print "bucket {0} does not exist".format(bucket_name)
                  return
              # Check if versioning is enabled
              response = s3_client.get_bucket_versioning(Bucket=bucket_name)
              status = response.get('Status','')
              if status == 'Enabled':
                  response = s3_client.put_bucket_versioning(Bucket=bucket_name,
                                                             VersioningConfiguration={'Status': 'Suspended'})
              paginator = s3_client.get_paginator('list_object_versions')
              page_iterator = paginator.paginate(
                  Bucket=bucket_name
              )

              for page in page_iterator:
                  print page
                  if 'DeleteMarkers' in page:
                      delete_markers = page['DeleteMarkers']
                      if delete_markers is not None:
                          for delete_marker in delete_markers:
                              key = delete_marker['Key']
                              versionId = delete_marker['VersionId']
                              s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=versionId)
                  if 'Versions' in page and page['Versions'] is not None:
                      versions = page['Versions']
                      for version in versions:
                          print version
                          key = version['Key']
                          versionId = version['VersionId']
                          s3_client.delete_object(Bucket=bucket_name, Key=key, VersionId=versionId)
              object_paginator = s3_client.get_paginator('list_objects_v2')
              page_iterator = object_paginator.paginate(
                  Bucket=bucket_name
              )
              for page in page_iterator:
                  if 'Contents' in page:
                      for content in page['Contents']:
                          key = content['Key']
                          s3_client.delete_object(Bucket=bucket_name, Key=content['Key'])
              #UNCOMMENT THE LINE BELOW TO MAKE LAMBDA DELETE THE BUCKET.  
              # THIS WILL CAUSE AN FAILURE SINCE CLOUDFORMATION ALSO TRIES TO DELETE THE BUCKET
              #s3_client.delete_bucket(Bucket=bucket_name)
              #print "Successfully deleted the bucket {0}".format(bucket_name)
              print "Successfully emptied the bucket {0}".format(bucket_name)



          def lambda_handler(event, context):
              try:
                  bucket = event['ResourceProperties']['BucketName']
                  if event['RequestType'] == 'Delete':
                      empty_delete_buckets(bucket)
                      #s3 = boto3.resource('s3')
                      #bucket.objects.all().delete()
                      #bucket = s3.Bucket(bucket)
                      #for obj in bucket.objects.filter():
                          #s3.Object(bucket.name, obj.key).delete()
                  sendResponseCfn(event, context, "SUCCESS")
              except Exception as e:
                  print(e)
                  sendResponseCfn(event, context, "FAILED")

          def sendResponseCfn(event, context, responseStatus):
              response_body = {'Status': responseStatus,
                               'Reason': 'Log stream name: ' + context.log_stream_name,
                               'PhysicalResourceId': context.log_stream_name,
                               'StackId': event['StackId'],
                               'RequestId': event['RequestId'],
                               'LogicalResourceId': event['LogicalResourceId'],
                               'Data': json.loads("{}")}
              requests.put(event['ResponseURL'], data=json.dumps(response_body))


      Description: cleanup Bucket on Delete Lambda Lambda function.
      # FunctionName: lambda_function
      Handler: index.lambda_handler
      Role : !GetAtt cleanupBucketOnDeleteLambdaRole.Arn
      Runtime: python2.7
      Timeout: 60


  cleanupBucketOnDeleteLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: !Join [ -, [!Ref 'AWS::StackName', 'cleanupBucketOnDeleteLambdaPolicy'] ]
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - logs:*
            - s3:*
            Resource: '*'
          - Effect: Deny
            Action:
            - s3:DeleteBucket
            Resource: '*'


  coderepo:
    Type: AWS::CodeCommit::Repository
    Properties:
      RepositoryName: !Sub "${AWS::StackName}"
      RepositoryDescription: "This repository holds the code that AWS CodePipeline will use to deploy."



  SourceEvent:
    Properties:
      Description: Rule for Amazon CloudWatch Events to detect changes to the source repository and trigger pipeline execution
      EventPattern:
        source:
        - aws.codecommit
        detail:
          event:
          - referenceCreated
          - referenceUpdated
          referenceName:
          - !Ref BranchName
          referenceType:
          - branch
        detail-type:
        - CodeCommit Repository State Change
        resources:
        - !GetAtt 'coderepo.Arn'
      State: ENABLED
      Targets: 
        - Arn: !Join
          - ':'
          - - arn
            - aws
            - codepipeline
            - !Ref 'AWS::Region'
            - !Ref 'AWS::AccountId'
            - !Ref 'Pipeline'
          Id: ProjectPipelineTarget
          RoleArn: !GetAtt 'CodeCloudWatchRole.Arn'
    Type: AWS::Events::Rule


  CodeCloudWatchRole:
    Description: IAM role to allow Amazon CloudWatch Events to trigger AWS CodePipeline execution
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - events.amazonaws.com
          Sid: 1
      Policies:
      - PolicyDocument:
          Statement:
          - Action:
            - codepipeline:StartPipelineExecution
            Effect: Allow
            Resource:
              - !Join
                - ':'
                - - arn
                  - aws
                  - codepipeline
                  - !Ref 'AWS::Region'
                  - !Ref 'AWS::AccountId'
                  - !Ref 'Pipeline'
        PolicyName: 'TriggerPipelinePolicy'
    Type: AWS::IAM::Role


  CodeBuildRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: ['sts:AssumeRole']
          Effect: Allow
          Principal:
            Service: [codebuild.amazonaws.com]
        Version: '2012-10-17'
      Path: /
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-CodeBuildAccess"
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - '*'
                Effect: Allow
                Resource: '*'


  PipelineRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: ['sts:AssumeRole']
          Effect: Allow
          Principal:
            Service: [codepipeline.amazonaws.com]
        Version: '2012-10-17'
      Path: /
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-CodePipelineAccess"
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Action:
                - 's3:*'
                - 'cloudformation:CreateStack'
                - 'cloudformation:DescribeStacks'
                - 'cloudformation:DeleteStack'
                - 'cloudformation:UpdateStack'
                - 'cloudformation:CreateChangeSet'
                - 'cloudformation:ExecuteChangeSet'
                - 'cloudformation:DeleteChangeSet'
                - 'cloudformation:DescribeChangeSet'
                - 'cloudformation:SetStackPolicy'
                - 'iam:PassRole'
                - 'sns:Publish'
                - 'codecommit:*'
                - 'codebuild:*'
                Effect: Allow
                Resource: '*'




############################################################################################################
#  BEGIN CodePipeline Definition
############################################################################################################





  Pipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      ArtifactStore:
        Location: !Ref 'ArtifactStoreBucket'
        Type: S3
      DisableInboundStageTransitions: []
      Name: !Sub "${AWS::StackName}"
      RoleArn: !GetAtt [PipelineRole, Arn]
      Stages:

        - Name: Fetch_Source
          Actions:
            - Name: SourceCode
              ActionTypeId:
                Category: Source
                Owner: AWS
                Provider: CodeCommit
                Version: '1'
              Configuration:
                BranchName: !Ref BranchName 
                PollForSourceChanges: false
                RepositoryName: !GetAtt coderepo.Name
              OutputArtifacts:
                - Name: code
              RunOrder: '1'


        - Name: Build_and_Deploy_System
          Actions:
            - Name: SAM_Build_and_SAM_Deploy
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              InputArtifacts:
                - Name: code
              Configuration:
                ProjectName: !Ref SAMBuildandSAMDeploy
              RunOrder: '1'
              OutputArtifacts:
                - Name: output-Build_and_Deploy_System

        - Name: Complete_Deployment
          Actions:
            - Name: Run_Finalizer
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              InputArtifacts:
                - Name: code
              Configuration:
                ProjectName: !Ref RunFinalizer
              RunOrder: '1'
              OutputArtifacts:
                - Name: output-RunFinalizer



############################################################################################################
#  END CodePipeline Definition
############################################################################################################


  StartAWSinstaller:
    Type: "AWS::CodeBuild::Project"
    Properties:
      Artifacts:
        Type: NO_ARTIFACTS
      Description: CodeBuild that will Clone from GitHub and push to CodeCommit to start Code Pipeline 
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/python:3.6.5
        Type: LINUX_CONTAINER
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 30
      Source:
        Type: NO_SOURCE
        BuildSpec: !Sub |
          version: 0.2
          phases:
            install:
              commands:
                - pwd
                - ls -al
                - pip install --upgrade pip
                - pip install -U boto3
                - apt-get install git
                - git config --global user.name StartAWSinstallerUser
                - git config --global credential.helper '!aws codecommit credential-helper $@'
                - git config --global credential.UseHttpPath true
            build:
              commands:
                - ls -al
                - git clone ${GitHubRepositoryHTTPSurl}
                - ls -al
                - cd amazon-s3-access-logs-to-elasticsearch/
                - ls -al
                - pwd
                - git checkout ${BranchName}
                - pwd
                - ls -al
                - git remote -v
                - git remote add aws ${coderepo.CloneUrlHttp}
                - git remote -v
                - git push aws ${BranchName}
                - ls -al
            post_build:
              commands:
                - echo ***** Build completed *****
                - echo ***** Code cloned from ${GitHubRepositoryHTTPSurl} *****
                - echo ***** Code was pushed to ${coderepo.CloneUrlHttp} *****




  SAMBuildandSAMDeploy:
    Type: "AWS::CodeBuild::Project"
    Properties:
      Artifacts:
        Type: CODEPIPELINE
      Description: CodeBuild that will use SAM to Build and Deploy the applicaiton 
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 30
      Source:
        BuildSpec: deployment/buildspec_SAM_Build_and_SAM_Deploy.yaml
        GitCloneDepth: 0
        Type: CODEPIPELINE
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        PrivilegedMode: false
        Image: pahud/aws-sam-cli
        Type: LINUX_CONTAINER
        EnvironmentVariables:
          - Name: codecommithttpsname
            Value: !GetAtt coderepo.Name
            Type: PLAINTEXT
          - Name: codecommithttpsurl
            Value: !GetAtt coderepo.CloneUrlHttp
            Type: PLAINTEXT
          - Name: deploymentartifactstorebucketname
            Value: !Ref 'ArtifactStoreBucket'
            Type: PLAINTEXT
          - Name: APP_STACK_NAME
            Value: !Sub "${AppStackName}"
            Type: PLAINTEXT


  RunFinalizer:
    Type: "AWS::CodeBuild::Project"
    Properties:
      Artifacts:
        Type: CODEPIPELINE
      Description: CodeBuild that will Run_Finalizer 
      # Name:
      #   Ref: MyCodeBuildProjectName
      ServiceRole: !Ref CodeBuildRole
      TimeoutInMinutes: 30
      Source:
        BuildSpec: deployment/buildspec_Run_Finalizer.yaml
        GitCloneDepth: 0
        Type: CODEPIPELINE
      Environment:
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/python:3.6.5
        Type: LINUX_CONTAINER
        EnvironmentVariables:
          - Name: FINALIZER_PROJECT_NAME
            Value: !Sub "${AppStackName}-Finalizer"
            Type: PLAINTEXT

############################################################################################################
############################################################################################################


Outputs:

  ArtifactStoreBucket:
    Description: The name of the AWS S3 deployment bucket
    Value: !Ref ArtifactStoreBucket


  coderepoURL:
    Description: The URL of the AWS CodeCommit Repository
    Value: !GetAtt coderepo.CloneUrlHttp


  coderepoName:
    Description: The Name of the AWS CodeCommit Repository
    Value: !GetAtt coderepo.Name



